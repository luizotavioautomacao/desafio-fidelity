# ğŸ—ï¸ Arquitetura do Sistema de Pesquisa Virtual (SPV)

## ğŸ¯ Objetivo

O **SPV (Sistema de Pesquisa Virtual AutomÃ¡tico)** Ã© uma soluÃ§Ã£o desenvolvida em **Python** para automatizar consultas de pesquisas nas plataformas de tribunais jurÃ­dicos do Brasil. O sistema realiza **web scraping automatizado** para verificar processos judiciais por **CPF, RG ou nome**.

---
### Stack Principal

* **Backend:** Python 3.8+
* **Banco de Dados:** PostgreSQL 12+ (migrado do MariaDB)
* **ORM:** SQLAlchemy 2.0
* **Web Scraping:** Selenium 4.15 com Microsoft Edge WebDriver
* **ContainerizaÃ§Ã£o:** Docker e Docker Compose
* **Testes:** Pytest com cobertura

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APRESENTAÃ‡ÃƒO                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚    CLI      â”‚  â”‚     API     â”‚  â”‚  Streamlit  â”‚          â”‚
â”‚  â”‚  (Scripts)  â”‚  â”‚  (Future)   â”‚  â”‚  (Future)   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    LÃ“GICA DE NEGÃ“CIO                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ SPVAutomaticoâ”‚  â”‚DatabaseServiceâ”‚  â”‚WebScraperServiceâ”‚   â”‚
â”‚  â”‚   (Core)     â”‚  â”‚   (Data)      â”‚  â”‚  (Scraping)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    CAMADA DE DADOS                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚ SQLAlchemy  â”‚  â”‚ PostgreSQL  â”‚  â”‚   Models    â”‚          â”‚
â”‚  â”‚   (ORM)     â”‚  â”‚  (Database) â”‚  â”‚  (Entities) â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‚ï¸ Modelo de Dados

O sistema utiliza um esquema PostgreSQL otimizado com as seguintes tabelas principais:

* **pesquisas**: Dados das pesquisas a serem realizadas
* **pesquisa_spv**: Resultados das pesquisas automatizadas
* **clientes**: InformaÃ§Ãµes dos clientes
* **funcionarios**: FuncionÃ¡rios responsÃ¡veis
* **lotes**: Agrupamentos de pesquisas
* **websites**: ConfiguraÃ§Ãµes dos tribunais
* **estados** e **servicos**: Dados de referÃªncia

### Melhorias no Esquema

1. **NormalizaÃ§Ã£o**: Estrutura mais limpa e eficiente
2. **Ãndices**: Performance otimizada para consultas frequentes
3. **Triggers**: AtualizaÃ§Ã£o automÃ¡tica de timestamps
4. **FunÃ§Ãµes**: Consultas complexas encapsuladas
5. **Views**: Consultas simplificadas para relatÃ³rios
6. **Constraints**: Integridade referencial garantida

---

## ğŸš€ Funcionalidades Principais

* Web Scraping Automatizado
* Suporte a mÃºltiplos tribunais (ex: TJSP)
* ConfiguraÃ§Ã£o flexÃ­vel via JSON
* Tratamento robusto de timeouts e erros

### Sistema de Filtros

* **Filtro 0:** Pesquisa por CPF
* **Filtro 1:** Pesquisa por RG
* **Filtro 2:** Pesquisa por Nome
* **Filtro 3:** Pesquisa por RG (alternativo)

### ClassificaÃ§Ã£o de Resultados

* **Resultado 1:** Nada consta
* **Resultado 2:** Criminal
* **Resultado 5:** CÃ­vel
* **Resultado 7:** Erro

### Processamento em Lotes

* PaginaÃ§Ã£o para grandes volumes
* Controle de prioridade
* ExecuÃ§Ã£o contÃ­nua ou por ciclos

---

## âš™ï¸ CaracterÃ­sticas TÃ©cnicas

* **Arquitetura Modular:** CÃ³digo organizado em serviÃ§os reutilizÃ¡veis
* **Logging Completo:** Sistema de logs para monitoramento
* **Tratamento de Erros:** GestÃ£o robusta de exceÃ§Ãµes
* **ConfiguraÃ§Ã£o FlexÃ­vel:** Suporte a diferentes tribunais
* **Performance Otimizada:** Ãndices e consultas otimizadas
* **ContainerizaÃ§Ã£o:** Suporte completo a Docker

---

## ğŸ“Š Monitoramento e MÃ©tricas

* Logs detalhados em console e arquivo
* Tratamento de erros com recuperaÃ§Ã£o automÃ¡tica

### 1. **MÃ©tricas de Performance**
- Tempo de execuÃ§Ã£o por pesquisa
- Taxa de sucesso/erro
- Throughput (pesquisas/minuto)
- Uso de recursos (CPU, memÃ³ria)

### 2. **MÃ©tricas de NegÃ³cio**
- Total de pesquisas processadas
- DistribuiÃ§Ã£o por tipo de resultado (pendentes, concluÃ­das, etc.)
- Pesquisas por cliente
- TendÃªncias temporais

### 3. **Alertas**
- Falhas de conexÃ£o
- Timeouts excessivos
- Erros de scraping
- Problemas de banco

---

## âœ… Qualidade de CÃ³digo

* Testes unitÃ¡rios com Pytest
* Cobertura de cÃ³digo

---

## ğŸ”„ Fluxo de ExecuÃ§Ã£o

### 1. **InicializaÃ§Ã£o**
```
1. Carregamento de configuraÃ§Ãµes (.env)
2. ConexÃ£o com banco PostgreSQL
3. InicializaÃ§Ã£o de serviÃ§os
4. VerificaÃ§Ã£o de dependÃªncias
```

### 2. **Ciclo de Pesquisa**
```
1. Busca pesquisas pendentes (paginaÃ§Ã£o)
2. Para cada pesquisa:
   a. Determina documento baseado no filtro
   b. Executa pesquisa no tribunal
   c. Analisa resultado
   d. Salva resultado no banco
   e. Atualiza status
3. Controle de tempo e limites
4. Tratamento de erros
```

### 3. **GestÃ£o de Filtros**
```
Filtro 0: CPF
Filtro 1: RG
Filtro 2: Nome
Filtro 3: RG (alternativo)

- ExecuÃ§Ã£o sequencial por prioridade
- Controle de disponibilidade de dados
- Fallback entre filtros
```

---

## ğŸ“ˆ ComparaÃ§Ã£o com VersÃ£o Original

| Aspecto | VersÃ£o Original | Nova VersÃ£o |
|---------|----------------|-------------|
| **Banco** | MariaDB | PostgreSQL |
| **ORM** | SQL direto | SQLAlchemy |
| **Arquitetura** | MonolÃ­tica | Modular |
| **PaginaÃ§Ã£o** | LIMIT fixo | PaginaÃ§Ã£o dinÃ¢mica |
| **Logging** | Print statements | Sistema estruturado |
| **ConfiguraÃ§Ã£o** | Hardcoded | VariÃ¡veis de ambiente |
| **Testes** | Nenhum | Testes unitÃ¡rios |
| **Deploy** | Manual | Docker |
| **Monitoramento** | Nenhum | MÃ©tricas completas |
| **Tratamento de Erros** | BÃ¡sico | Robusto |

---

## ğŸ¯ ConclusÃ£o

A nova arquitetura do Sistema SPV representa uma evoluÃ§Ã£o significativa em termos de:

- **Performance**: Processamento mais eficiente
- **Escalabilidade**: Suporte a crescimento
- **Manutenibilidade**: CÃ³digo mais limpo e organizado
- **Robustez**: Melhor tratamento de erros
- **Monitoramento**: Visibilidade completa do sistema

O sistema estÃ¡ preparado para crescer e se adaptar Ã s necessidades futuras, mantendo a compatibilidade com os requisitos originais enquanto adiciona capacidades modernas de desenvolvimento e operaÃ§Ã£o. 

---

### ğŸ”® Roadmap e Melhorias Futuras

* API REST para integraÃ§Ã£o
* Dashboards com Streamlit
* Suporte a mais tribunais
* Celery para tasks assÃ­ncronas
* Monitoramento avanÃ§ado (Prometheus, ELK Stack para logs, Kafka, Grafana)
* Redis para cache

#### ğŸ› ï¸ Pipeline AnalÃ­tico e Dados

Para evoluÃ§Ã£o analÃ­tica do SPV, recomenda-se a construÃ§Ã£o de um pipeline de dados moderno, incluindo:

- **ETL/ELT Automatizado:** Ferramentas como Airbyte, Fivetran ou scripts Python para extraÃ§Ã£o de dados do PostgreSQL e ingestÃ£o em Data Lake/Data Warehouse.
- **TransformaÃ§Ã£o e Modelagem com dbt:** OrganizaÃ§Ã£o dos dados em camadas (staging, marts, dimensÃµes e fatos) para facilitar anÃ¡lises e relatÃ³rios.
- **Data Warehouse (Star Schema):** Estrutura centralizada para anÃ¡lises histÃ³ricas, com tabelas fato e dimensÃµes (ex: fato_pesquisas, dim_cliente, dim_servico).
- **Materialized Views e IndexaÃ§Ã£o:** Para acelerar consultas analÃ­ticas e relatÃ³rios de BI.
- **Versionamento de Dados:** Tabelas de histÃ³rico (SCD) para rastrear mudanÃ§as e garantir auditoria.
- **Armazenamento Externo de Anexos:** Upload de arquivos para S3/GCS e referÃªncia por URL no banco.
- **Metadados FlexÃ­veis:** Uso de colunas JSONB para atributos dinÃ¢micos em tabelas como servicos.
- **Dashboards (Metabase, Power BI, Superset, Streamlit):** VisualizaÃ§Ã£o de mÃ©tricas de negÃ³cio, performance e operaÃ§Ã£o, com queries otimizadas e filtros dinÃ¢micos.
- **OrquestraÃ§Ã£o com Airflow:** AutomatizaÃ§Ã£o de todo o pipeline, desde a extraÃ§Ã£o atÃ© a atualizaÃ§Ã£o de dashboards.

Essas prÃ¡ticas permitem:
- AnÃ¡lises histÃ³ricas e operacionais
- MÃ©tricas de performance e negÃ³cio em tempo real
- GovernanÃ§a e rastreabilidade dos dados
- Escalabilidade para grandes volumes

#### ğŸ›¡ï¸ SeguranÃ§a

* Criptografia de dados sensÃ­veis
* Controle de acesso ao banco
* Backup seguro
* Firewall e VPN
* Monitoramento de seguranÃ§a

#### ğŸ—ï¸ Arquitetura
* MicroserviÃ§os
* Message Queues
* Load Balancing
* Auto-scaling
* CI/CD
